---
title:  "TP2 Linear Models"
author: "A.V Hurtado Quiceno"
date: "2/5/2023"
output:
  html_document:
      toc: TRUE
  pdf_document: 
      
      toc: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

rm(list = ls())

library(FactoMineR)
library(utils)
library(stats)
library(ggiraphExtra)
library(measurements)
library(dplyr)
library(corrplot)
library(kableExtra)
library(dplyr)
library(factoextra)
library(car)
library(ellipse)
library(devtools)
library(webshot)
library(tidyverse)
library(SimDesign)
library(tidyverse)
library(ISwR)
library(MASS)
library(Sleuth3)
library(tidyr)
```

install.packages(c("ggplot2", "dplyr", "ISwR", "MASS", "Sleuth3", "rmarkdown", "tidyr"))


```{css, echo=FALSE}
pre {
  max-height: 300px;
  overflow-y: auto;
}

pre[class] {
  max-height: 100px;
}
```

```{css, echo=FALSE}
.scroll-100 {
  max-height: 100px;
  overflow-y: auto;
  background-color: inherit;
}
```



# Introduction Ozone Data

$\textbf{Objective:}$ L'objective est d'expliquer la variable ```max03``` par rapport a ```T12``` dans le modele lineare et par rapport a     dans le modele multiple et faire un comparison avec le deux. 


```{r, include=FALSE, echo=FALSE}
ozone1 <- read.table("ozone.txt", header = TRUE, sep=";")
ozone1
ozone <- ozone1[,-1]
ozone
```

```{r, echo=FALSE}
head <- head(ozone1, 5)

kable(head, caption="Le 5 premier colonnes de la data frame Ozone", booktabs = TRUE, valign = 't') %>% kable_styling(latex_options = "striped") 
```

ou les varaibles sont:

 * ``` obs```: mois-jour 
 
 * ```maxO3```: teneur maximale en ozone observée sur la journée (en $\mu g r / m 3)$;
 
 * ```T6```, .. ,```T18```: température observée à $6 \mathrm{~h}, \ldots 18 \mathrm{~h}$;
 
 * ```Ne6```, .., ```Ne18```: nébulosité observée à $6 \mathrm{~h}, \ldots, 18 \mathrm{~h}$;
 
 * ```$\mathrm{Vx}$```: composante est-ouest du vent ;
 
 * ```maxO3v```: teneur maximale en ozone observée la veille ;
 
 * ```vent```: orientation du vent à $12 \mathrm{~h}$;
 
 * ```pluie```: occurrence ou non de précipitations.




# Modèle linear simple $\mathcal{M}_{1}$ avec la varialble ```T12```




On considére el modèle lineaire simple $\mathcal{M}_{1}$ avec la variable explicative ```T12```. 


\begin{equation}
(\mathcal{M}_{1}): max03= \beta_{0} + \beta_{1} T12 + \epsilon_{1}
\end{equation}





## Résumé {.tabset}


### Plot 

```{r, echo=FALSE, include=FALSE}
## this attach is important:

attach(ozone)
#ozone
plot(maxO3,T12)
```

```{r, echo=FALSE,  fig.dim=c(5, 3)}
#plot(T12,maxO3, xlab="T12", ylab="max03", color="red")
## it is not good, so we cannot do that abline
#abline(res_simple,col="red")## la droite de regression


p2 <- ggplot(data=ozone, aes(x=T12, y=maxO3v)) + geom_point(shape=1,  color="darkred", size=3) 
p2
```


```{r, echo=FALSE, include=FALSE}
res_simple <- lm(maxO3~T12)##intercept est ajouté par default
res_simple
```


### Scatter plot



```{r, echo=FALSE}
## 4.1: Plot a scatter plot for the variables with T12 on the x-axis
## maxo3 on the y-axis

ggplot(data=ozone, aes(x= T12, y=maxO3)) +
  geom_point()+
  stat_smooth()
```


### Correlation

Ici on etude la correlation entre les deux variables ```T12``` et ```maxo3```, on a que le valuer est $0.492$ i.e que on peut expliquer la variable ```maxo3``` par la variable  ```T12```


```{r,echo=FALSE}
cor(ozone$T12, ozone$maxO3) 
```



### Summary 

```{r, echo=FALSE,  fig.dim=c(5, 3)}
#summary
summary(res_simple)

```
### Coefficients

```{r, echo=FALSE,  fig.dim=c(5, 3)}
coefficiensimple <- res_simple$coefficients
coefficiensimple

```


Les estimations des coefficients sont $\beta_0$ et $\beta_1$ sont respectivement $\beta_0=28.2761$ et $\beta_1=2.6254$. L'équation de la regression lineaire est:


$$y=28.2761+2.6254 \,\, T12. $$



### Residuals


```{r, class.output="scroll-100",  fig.dim=c(5, 3)}

#Le residuals sont:

residuals_simple <- res_simple$residuals
residuals_simple




```

### Fitted Values

```{r, class.output="scroll-100", fig.dim=c(5, 3)}
#Le fitted values sont:

fitted_simple <- res_simple$fitted
fitted_simple

```


### The means

```{r, echo=FALSE}
meanresi1 <- mean(res_simple$residuals)
cat("The mean of the residuals is", meanresi1)

meanfitted1<- mean(res_simple$fitted)
cat("The mean of the fitted values is", meanfitted1)


```


### $R^{2}$ squared et $R^{2}_{a}$ adjusted


```{r, echo=FALSE, fig.dim=c(5, 3)}
R_simple <- summary(res_simple)$r.squared
cat(" Le R2 est value est",R_simple )


#print(summary(res_simple)$r.squared)
R_simple_adjusted <- summary(res_simple)$adj.r.squared

cat(" Le R2 adjusted value est", R_simple_adjusted )
 
```


# Modèle linear multiple $\mathcal{M}_{2}$ avec les variables ```T12```, ```Vx```, ```N12``` and ```max03v```


On considére el modèle lineaire simple $\mathcal{M}_{2}$ avec la variable explicative ```T12```, ```Vx```, ```N12``` and ```max03v```.


\begin{equation}
(\mathcal{M}_{2}): max03= \beta_{0} + \beta_{1} T12 + \beta_{1} Vx  + \beta_{1} N12  + \beta_{1} T12max03V + \epsilon_{2}
\end{equation}


## Résumé {.tabset}


### Plot

```{r, echo=FALSE}
res_multiple <- lm( maxO3 ~ T12 + Vx + Ne12 + maxO3v, data = ozone)

#plot(res_multiple$fitted.values,res_multiple$residuals,xlab = "Fitted", ylab = "Res")

Fitted <- res_multiple$fitted.values
Residuals <- res_multiple$residuals

p1 <- ggplot(data=ozone, aes(x=Fitted, y=Residuals)) + geom_point(shape=1,  color="darkred", size=3) 
p1
```


### Summary

```{r,  echo=FALSE}
# This is the linear model of the model (M1):
#attach(graissed)
res_multiple <- lm( maxO3 ~ T12 + Vx + Ne12 + maxO3v, data = ozone)
#res_multiple
summary(res_multiple)
#ggPredict(res6,se=TRUE,interactive=TRUE)
```

### Coefficients

```{r, echo=FALSE,  fig.dim=c(5, 3)}
coefficienmultiple <- res_multiple$coefficients
coefficienmultiple

```

Les estimations des coefficients sont $\beta_0, \beta_1, \beta_2, \beta_3$ et $\beta_4$ sont respectivement $\beta_0=32.76618, \beta_1=0.70387$, $\beta_2=0.93921, \beta_3=-2.55848$ et $\beta_4=0.59597$. Le modele lineaire $\mathcal{M}_{2}$ est: 


$$y=32.76618+0.70387 \,\, T12 + 0.93921 \,\, Vx -2.55848 \,\, Ne12 +0.59597 \,\, maxO3v.$$




### Residuals


```{r, class.output="scroll-100",  fig.dim=c(5, 3)}

#Le residuals sont:

residuals_multiple <- res_multiple$residuals
#residuals_multiple


```


### Fitted Values

```{r, class.output="scroll-100", fig.dim=c(5, 3)}
#Le fitted values sont:

fitted_multiple <- res_multiple$fitted
#fitted_multiple

```

### The means

```{r, echo=FALSE}
## fitted values
fitted_multiple <- res_multiple$fitted
#fitted
## Residuals
residuals_multiple <- res_multiple$residuals
#residuals
meanfitted<- mean(fitted_multiple)
cat("The mean of the fitted values is", meanfitted)
meanresi <- mean(residuals_multiple)
cat("The mean of the residuals is", meanresi)

```

### $R^{2}$ squared et $R^{2}_{a}$ adjusted


```{r, echo=FALSE, fig.dim=c(5, 3)}
R_multiple <- summary(res_multiple)$r.squared
cat(" Le R2 est value est",R_multiple )


#print(summary(res_simple)$r.squared)
R_multiple_adjusted <- summary(res_multiple)$adj.r.squared

cat(" Le R2 adjusted value est", R_multiple_adjusted )
 
```


# Modèle lineaire avec tout les variables

On considere le modèle lineaire avec tout les variables explicatives

## Resume {.tabset}

### Summary

```{r, echo=FALSE}
res_tous <-lm(maxO3~., data = ozone)
summary(res_tous)

#print(summary(res_simple)$r.squared)
R_multiple_adjusted_tous <- summary(res_tous)$adj.r.squared

cat(" Le R2 adjusted value est", R_multiple_adjusted_tous)
 
```




```{r, echo=FALSE, include=FALSE}
R_tous <- summary(res_tous)$adj.r.squared
cat(" Le R2 est value est",R_tous)
```



# Analysis 


$\textbf{Resume Modèle}$ $\mathcal{M}_{1}:$

1. Est-ce le modele $\mathcal{M}_{1}$ vous semple-t-il adapte et $\mathcal{M}_{2}$:

 * Dans le modele de regression simple on a que $R^{2}_{\mathcal{M}_{1}}= 24\%$, on peut concluire que les modele n'est pas adapte, mais dans le modele de regression multiple on a que $R^{2}_{\mathcal{M}_{2}} = 66\%$ alors on peut concluire que le modele est meiller adapte, en plus, on n’observe pas de forme particulière avec le nuage des points. On montre que les variables ajoutées qui sont ``` V x```, ```Ne12```, ```maxO3v``` contribue à mieux expliquer le modele. 
 

$\textbf{Observation}:$ $R^2$ augmente avec chaque prédicteur ajouté à un modèle. Comme $R^2$ augmente toujours et ne diminue jamais, il peut sembler être un meilleur ajustement avec le plus de termes que vous ajoutez au modèle. Mais ce n’est pas toujours le meilleur choix. 


2. Est-ce qu'on valide a chaque fois le modele global ? les variables explicatives 

 * On voit que seul les variables que sont significatives dans le modele sont $\beta_0$, ```T6```, ```T12```, ```Ne9``` ,  ```Ne12````, ```Vx``` et ```maxO3v```` sont significative dans le modèle. On voit aussi que
le valeur de $R^2$ a augmenté de $0.0204365$ i.e $2.4 \%$ seulement.


# Intervalles de Confiance {.tabset}

Considérer maintenant le modèle $\mathrm{M}_2$. Calculer les intervalles de confiance pour chaque coefficient (créer une fonction si possible). Vous pouvez utiliser la fonction coef de la façon suivante pour récupérer directement les estimations des coefficients avec les statistiques et \$df.residual pour récupérer directement les degrés de liberté nécéssaires dans le calcul des intervalles de confiance:


## Coefficiets
```{r, echo=FALSE}
res2<- lm(maxO3 ~T12 +Vx + Ne12 + maxO3v, data=ozone)
coef <- summary(res2)$coef
coef
```

## Degres de liberte

```{r, echo=FALSE}
## Degres de liberte:
degre_res_multiple <- res2$df.residual
cat("Les degres de liberte", degre_res_multiple)
```

## Intervalles de Confiance avec confit

```{r, echo=FALSE}
# Find the confidence interval
IC3 <-confint(res2, level=0.95)
IC3

```

## Intervalles de Confiance a la main

Cette fonction calcule l'intervalle de confiance


```{r}
#Hacer una funcion que calcule los intervalos de confianza.
#the estimae +-std.error *qt(0.96,degrefreedom )

# With alpha the significance level


conf_int <- function(model, alpha=0.05) {
  # Extract the coefficients and their standard errors from the model summary
  coef_summary <- summary(model)$coefficients
  coef_values <- coef_summary[, 1]
  coef_se <- coef_summary[, 2]
  
  # Compute the t-values for the given confidence level
  t_values <- qt(1 - alpha / 2, df = model$df.residual)
  
  # Compute the confidence intervals for each coefficient
  lower_bounds <- coef_values - t_values * coef_se
  upper_bounds <- coef_values + t_values * coef_se
  
  # Combine the lower and upper bounds into a matrix and add column names
  conf_int <- cbind(lower_bounds, upper_bounds)
  colnames(conf_int) <- c("Lower Bound", "Upper Bound")
  
  # Return the confidence intervals
  return(conf_int)
}


conf_int(res_multiple)

```

Cette focntion ici, c'est l'intervalle de confiance avec R

```{r}
IC<-confint(res_multiple,level = 0.95)
IC
```


## L’ellipse de confiance de 95%


Dessinez les ellipses de confiance (à 95\%) des paramètres $\beta$ considérés deux à deux et sur chaque ellipse le rectangle de confiance construit à partir de chaque intervalle de confiance pris séparement.

```{r, echo=FALSE, include=FALSE}
par(mfrow=c(2,2))
for(i in 1:4){
 for(j in (i+1):5){
  plot(ellipse(res_multiple,c(i,j),level=0.95),type="l",
   xlab=paste("beta",i,sep=""),ylab=paste("beta",j,sep=""))
  points(coef(res_multiple)[i], coef(res_multiple)[j],pch=3)
 # lines(c(IC3[1,i],IC3[1,i],IC3[2,i],IC3[2,i],IC3[1,i]),
  # c(IC3[1,j],IC3[2,j],IC3[2,j],IC3[1,j],IC3[1,j]),lty=2)
 }
}

```



```{r,echo=FALSE}
par(mfrow=c(3,2),mar=c(4, 4, 0,3))
for (i in 1:3){
for (k in (i+1):4){
plot(ellipse(res_multiple,c(i,k),level = 0.95),type="l",
xlab=paste("beta",i,sep = "_"),ylab=paste("beta",k,sep = "_"))
points(coef(res_multiple)[i],coef(res_multiple)[k],pch=1)
lines(c(IC[i,1],IC[i,1],IC[i,2],IC[i,2],IC[i,1]),
c(IC[k,1],IC[k,2],IC[k,2],IC[k,1],IC[k,1]),lty=2)
}}


```


```{r, include=FALSE}
par(mfrow = c(2,2))
for (i in 1:4) {
  for (j in (i+1):5) {
    # get ellipse coordinates
    ellipse_coords <- ellipse(res_multiple, c(i,j), level = 0.95)
    ellipse_coords[1]
    # check if ellipse coordinates are empty
    if (is.null(ellipse_coords)) {
      # skip this plot if ellipse coordinates are empty
      next
    }
    
    # plot ellipse
    plot(ellipse_coords, type = "l",
         xlab = paste("beta", i, sep = ""), ylab = paste("beta", j, sep = ""))
    points(coef(res_multiple)[i], coef(res_multiple)[j], pch = 3)
    
    # calculate confidence intervals
    z <- qnorm(1 - 0.05/2)
    CI_i <- summary(res_multiple)$coefficients[i, 2] * z
    CI_j <- summary(res_multiple)$coefficients[j, 2] * z
     
  lines(c(mean(ellipse_coords[1]) - CI_i, mean(ellipse_coords[1]) + CI_i),
          c(mean(ellipse_coords[2]), mean(ellipse_coords[2])), lty = 2)
    lines(c(mean(ellipse_coords[1]), mean(ellipse_coords[1])),
          c(mean(ellipse_coords[2]) - CI_j, mean(ellipse_coords[2]) + CI_j), lty = 2)
  }
}

```







```{r, include=FALSE}
# Generate data for the covariance matrix
set.seed(123)
x <- rnorm(100)
y <- 2*x + rnorm(100)

# Fit a linear regression model
model <- lm(y ~ x)

# Compute the covariance matrix of the model
cov_mat <- vcov(model)

# Compute the coefficients of the model
coef <- coef(model)

# Compute the standard errors of the coefficients
se <- sqrt(diag(cov_mat))

# Set the level of probability for the ellipse
prob_level <- 0.95

# Compute the ellipse coordinates
ellipse_coords <- ellipse::ellipse(cov_mat, coef, level = prob_level)

# Compute the confidence interval lines
x_lwr <- coef[1] - qnorm((1-prob_level)/2) * se[1]
x_upr <- coef[1] + qnorm((1-prob_level)/2) * se[1]
y_lwr <- coef[2] - qnorm((1-prob_level)/2) * se[2]
y_upr <- coef[2] + qnorm((1-prob_level)/2) * se[2]

# Plot the ellipse with the confidence interval lines
plot(ellipse_coords, type = "l", xlab = "x", ylab = "y")
abline(h = y_lwr, lty = 2)
abline(h = y_upr, lty = 2)
abline(v = x_lwr, lty = 2)
abline(v = x_upr, lty = 2)
```

```{r, include=FALSE}
par(mfrow=c(2,2))
for(i in 1:4){
 for(j in (i+1):5){
   ellipse_coords <- ellipse(res_multiple,c(i,j),level=0.95)
    ellipse_coords
    
  plot(ellipse(res_multiple,c(i,j),level=0.95),type="l",
   xlab=paste("beta",i,sep=""),ylab=paste("beta",j,sep=""))
  points(coef(res_multiple)[i], coef(res_multiple)[j],pch=3)
 # lines(c(IC3[1,i],IC3[1,i],IC3[2,i],IC3[2,i],IC3[1,i]),
  # c(IC3[1,j],IC3[2,j],IC3[2,j],IC3[1,j],IC3[1,j]),lty=2)
 }
  }
```

# Propriété de sans biais des estimateurs de coefficients $\beta_{j}$

Vérification de la propriété de sans biais des estimateurs de coefficients $\beta_j$ d'un modèle linéaire et calcul des taux de couverture

Nous allons tester dans cette section que les estimateurs de coefficients $\beta$ d'un modèle linéaire sont sans 
biais. En pratique, on ne peut jamais réaliser cela. On va simuler cela lors du TP. On considère pour cela que la 
table ozone est notre population d'étude, on connait donc les vraies valeurs des coefficients $\beta$ (cela n'est 
jamais possible en pratique car on n'a jamais la population d'étude). Dans cette population, nous allons tirer des 
échantillons aléatoires de taille $n=200$ et on va s'interesser à l'estimation du coefficient de la variable T12 qui 
est égal à:

# Echantionage {.tabset}

## Le valeur de ```T12```

```{r, echo=FALSE}
T12 <- res2$coefficients[2]

cat("Le vrai valeur de T12 est:", T12)
```
## Echantionage avec $n=200$ observations

```{r, echo=FALSE}
N <- nrow(ozone)
n<- 200
s <- sample(N,n)
s
```

## Valeur de ```T12```

```{r, echo=FALSE, include=FALSE}
set.seed(123)
ozone.s <- ozone[s,]
ozone.s
```


```{r, echo=FALSE}
res2.s <- lm(maxO3 ~T12 + Vx + Ne12 +maxO3v, data=ozone.s)
res2.s
res2.s$coefficients[2]

```

# Question 1  {.tabset}


Considérer 10000 échantillons comme ci-dessus et calculer pour chaque échantillon l'estimation du coefficient de T12. Mettez ces estimations dans un vecteur de taille 10000.

$\textbf{Answer:}$

Ici nous montrons juste la première ligne du $10000$ et $20000$ echantillons. 

## 10000 Echantillon avec $n=200$ observations

```{r}
nsim <- 10000
echantillon <- numeric(10000)
confinterval <- c()

for (i in 1:10000)
{
#sample with 200 observations
N <- nrow(ozone)
n <- 200
s <- sample(N,n)

ozone.s <- ozone[s,]
ozone.s

res2.s <- lm(maxO3 ~T12 + Vx + Ne12 +maxO3v, data=ozone.s)
rescof <- res2.s$coefficients[2]

## Interval de confiance
confinterval <- append(confinterval,confint(res2.s,level=0.95)[2,])


echantillon[i] <- rescof
}

head(echantillon)
#echantillon
```





## 20000 Echantillon avec $n=200$ observations



```{r, echo=FALSE}
nsim <- 20000
echantillon2 <- numeric(20000)
for (i in 1:20000)
{
#sample with 200 observations
N <- nrow(ozone)
n <- 200
s <- sample(N,n)

ozone.s <- ozone[s,]
ozone.s

res2.s <- lm(maxO3 ~T12 + Vx + Ne12 +maxO3v, data=ozone.s)
rescof <- res2.s$coefficients[2]

echantillon2[i] <- rescof
}

head(echantillon2) 

```

## 10000 Echantillon avec $n=400$ observations

```{r, echo=FALSE}
nsim <- 10000
echantillon1 <- numeric(10000)
confinterval <- c()

for (i in 1:10000)
{
#sample with 200 observations
N <- nrow(ozone)
n <- 400
s <- sample(N,n)

ozone.s <- ozone[s,]
ozone.s

res2.s <- lm(maxO3 ~T12 + Vx + Ne12 +maxO3v, data=ozone.s)
rescof <- res2.s$coefficients[2]

## Interval de confiance
confinterval <- append(confinterval,confint(res2.s,level=0.95)[2,])


echantillon1[i] <- rescof
}

head(echantillon1)


```

## Function que depend de m nombre de simulation et r nombre des observations


```{r}

## n is the number of simulations:

echantillonvector <- function(m,r){
  
 nsim <- m
 echantillon <- numeric(m)
for (i in 1:m)
{
#sample with 200 observations
N <- nrow(ozone)
n <- r
s <- sample(N,n)

ozone.s <- ozone[s,]
ozone.s

res2.s <- lm(maxO3 ~T12 + Vx + Ne12 +maxO3v, data=ozone.s)
rescof <- res2.s$coefficients[2]

echantillon[i] <- rescof
}
return(echantillon)
}

echantillon3 <- echantillonvector(10000,400)
head(echantillon3)


```





# Question 2  {.tabset}

 Calculer la moyenne de ces 10000 estimations et comparer avec la vrai valeur du coeffcient. Si ces deux valeurs sont très proches, on peut décider que l'estimateur est sans biais. Pour nous aider, on peut calculer le biais relatif de $\hat{\beta}$ :


$$
RB(\hat{\beta})=\frac{\frac{1}{10000} \sum_{i=1}^{10000} \hat{\beta}^{(i)}-\beta}{\beta},
$$
où $\hat{\beta}^{(i)}$ est une estimation du paramètre $\beta$ à partir de ième échantillon et $\beta$ est la vraie valeur du paramètre.

On peut aussi représenter graphiquement la moyenne des estimations (voir figure plus bas). Attention, le calcul du biais relatif nous dit que la courbe est assez proche de la ligne en rouge qui est le vrai beta.

$\textbf{Answer:}$

a). La moyenne de ces 10000 et 20000 estimations:

## Le valeur de T12

```{r}

## Le vrai valeur de T12

cat("Le vrai valuer del coefficient correspondant a T12 est: ", T12)

```


## Le means

```{r}
#10000
mean1 <- mean(echantillon)

cat("Le moyenne de 10000 echantillonage est ", mean1)

## 20000
mean2 <- mean(echantillon2)

cat("Le moyenne de 20000  est ", mean2)

## 10000 avec n=400

mean3 <- mean(echantillon3)

cat("Le moyenne de 20000 echantillonage avec n=400 pbservations est ", mean3)
```

$\textbf{Conclusion}$ Comme le vrai valeur et les valeurs de 10000 et 20000 echantionage sont tres proche, on peut concluire que le estimateur est sans biais.



## Le bias avec la focntion de R

b). Le biais relatif de $\hat{\beta}$ est different chaque fois:

```{r}
#biais del echantillon 10000
bi1 <- bias(echantillon, T12)
cat("Le bias de 10000 echantillonage avec n=200 avec R:",bi1 )


#biais del echantillon 20000
bi2 <- bias(echantillon2, T12)
cat("Le bias de 20000 echantillonage avec n=200 avec R:",bi2 )

#biais del echantillon 20000 avec n=400 observations 

bi2 <- bias(echantillon3, T12)
cat("Le bias de 10000 echantillonage avec n=400 observations avec R:",bi2 )

```

## Le bias a la main

```{r}
#EL VALOR MENOS EL DE ECHANTILLON 
bia1 <- mean(echantillon) - T12
cat("Le bias de 10000 echantillonage avec n=200 est", bia1)

bia2 <- mean(echantillon2) - T12
cat("Le bias de 20000 echantillonage avec n=200", bia2)


bia3 <- mean(echantillon3) - T12
cat("Le bias de 10000 echantillonage avec n=400 observations est", bia3)

```


## Graphe

c). Graphe moyenne en terms de nombre de simulations

```{r, echo=FALSE}

## n is the number of simulations:

meanfunction <- function(m){
  
 nsim <- m
 
echantillon <- numeric(m)## 2 colonne , 10000 linies

for (i in 1:m)
{
#sample with 200 observations
N <- nrow(ozone)
n <- 200
s <- sample(N,n)

ozone.s <- ozone[s,]
ozone.s

res2.s <- lm(maxO3 ~T12 + Vx + Ne12 +maxO3v, data=ozone.s)
rescof <- res2.s$coefficients[2]

echantillon[i] <- rescof
#echantillon[i,1]<- resconf
# recoit le ecart type, 
# echantillon[i,2] <- 

}
 
mean(echantillon)
  
}



```



```{r, echo=FALSE, include=FALSE}
# seq(from=1,to=10,by=2)

#n = seq(10, 2000, 10)
#res = sapply(n, meanfunction)
#ts.plot(res)

#res1 <- readRDS("figure.rds", refhook = NULL)

#res1 

#ts.plot(res1)
```



```{r}
# 10000 nombre de simulations avec n=200
plot( cumsum(echantillon)/(1:10000), type="l" ,xlab = "Nombre Simulations ", ylab = " Moyennes des estimateurs de beta de T12" )
abline(h=T12, col="red")


# 20000 nombre de simulations avec n=200
plot( cumsum(echantillon2)/(1:20000), type="l" ,xlab = "Nombre Simulations ", ylab = " Moyennes des estimateurs de beta de T12" )
abline(h=T12, col="red")


# 10000 nombre de simulations avec n=400
plot( cumsum(echantillon3)/(1:10000), type="l" ,xlab = "Nombre Simulations ", ylab = " Moyennes des estimateurs de beta de T12" )
abline(h=T12, col="red")

```





# Question 3  {.tabset}

3. On veut calculer maintenant le taux de couverture des intervalles de confiance de $\beta_{T 12}$. Il faut donc, pour chanque échantillon, regarder si $\beta_{T 12}$ appartient à l'intervalle de confiance construit à partir de cet échantillon et obtenir ensuite le taux de couverture (nombre d'échantillons qui contiennent $\beta_{T 12}$ divisé par 10000). Inspirez vous du point précédent pour calculer ce taux de couverture. Le mieux est de faire les deux calculs sur les mêmes échantillons (biais et taux de couverture).


$\textbf{Answer:}$

```{r, echo=FALSE, include=FALSE}

confidence_interval_Andy <- function(vector, interval) {
  # Standard deviation of sample
  vec_sd <- sd(vector)
  # Sample size
  n <- length(vector)
  # Mean of sample
  vec_mean <- mean(vector)
  # Error according to t distribution
  error <- qt((interval + 1)/2, df = n - 1) * vec_sd / sqrt(n)
  # Confidence interval as a vector
  result <- c("lower" = vec_mean - error, "upper" = vec_mean + error)
  return(result)
}

```


```{r}
beta <- T12

#echantillon
vecteurinter <- c()

#vecteurinter <- append(vecteurinter, confinterval[1] > beta && confinterval[2]>beta)
for (i in 1:10000){
  k=i-1 
  vecteurinter <- append(vecteurinter, isTRUE(beta>confinterval[i+k] && beta<confinterval[i+k+1]))
  }

taux <- mean(vecteurinter)
cat("Le taux de couverture des intervalles de confiance de beta_{T 12} est:", taux)
```




```{r, echo=FALSE, include=FALSE}
# Test of the confidence interval of a vector
beta <- T12

#echantillon
vecteurinter <- c()

#vecteurinter <- append(vecteurinter, confinterval[1] > beta && confinterval[2]>beta)
for (i in 1:10000){
  k=i-1 
  vecteurinter <- append(vecteurinter, isTRUE(beta>confinterval[i+k] && beta<confinterval[i+k+1]))
  }

taux <- mean(vecteurinter)


#TrueFalsetableEchantillonGFixe1 <- data.table::between(T12, mat4[, 1], mat4[, 2])
#TrueFalsetableEchantillonGFixe1
  
  
#nombreTRUE <- length(TrueFalsetableEchantillonGFixe1[TrueFalsetableEchantillonGFixe1== TRUE])


cat("Le taux de couverture des intervalles de confiance de beta_{T 12} est:", taux)

```






# Bootstrap {.tabset}
Le modèle utilisé est $Y=X \beta+\varepsilon$ où $\varepsilon$ est une variable aléatoire de loi $F$ inconnue et d'espérance nulle. L'idée du bootstrap est d'estimer cette loi par ré-échantillonnage.


```{r, echo=FALSE, include=FALSE}
ozoneb <-read.table("ozone.txt", header =TRUE, sep=";")
ozoneb <-ozoneb[,-1]
attach(ozoneb)
```

On considere le modele suivante:

$$ maxo3 = \beta_{0} + \beta_{1} T12 + \beta_{2} Vx + \beta_{3} Ne12$$


```{r, echo=FALSE}
modele3<-lm(maxO3~T12+Vx+Ne12,data = ozoneb)
summary(modele3)
```




## Les residus estimés


On calcule les residus estimes $\hat{\epsilon} = \hat{Y} -Y$ et ajustements $\hat{Y}$. 

```{r}
res<-residuals(modele3)
y_chapeau <-predict(modele3)
COEFF <-matrix(0, ncol = 4,nrow = 10000)
colnames(COEFF) <-names(coef(modele3))
ozone.boot<-ozoneb

```

On applique la methode de bootstrap avec 10000 ($dim(COEF)$) echantillons bootstrapes:

```{r}
for (i in 1:nrow(COEFF)){
Regetoile <- sample(res,length(res),replace=T)
mod_etoile<-y_chapeau + Regetoile
ozone.boot[,"T12"] <-mod_etoile
modele3boot<-lm(formula(modele3),data = ozone.boot)
COEFF[i,] <-coef(modele3boot) # On obtient une matrice de 1000 coefficients estimés
}

```

## Confidence Interval

Nous avons obtenu un matrice de 10000 coefficients estimés (```COEF```) et nous choisir les quantiles empiriques a $2.5\%$ et $97.5\%$. 



```{r, echo=FALSE}
 b2<-apply(COEFF,2,quantile,probs=c(0.025,0.975))
b2
```

Un IC de $95\%$ pour le coefficient ```T12``` est donc donné pas $[0.045,0.146]$. 

## Histogram 

Cette histogramme semble indiquer que la loi est proche d'une loi normale. 

```{r, echo=FALSE, include=FALSE}

print(COEFF[,"T12"])
```

```{r}
hist(COEFF[,"T12"],main="",xlab="Coefficient de T12")
```


























































```{r, include=FALSE}
compute_CI <- function(model, level = 0.95) {
  # Compute the covariance matrix of the model
  cov_mat <- vcov(model)

  # Compute the coefficients of the model
  coef <- coef(model)

  # Compute the standard errors of the coefficients
  se <- sqrt(diag(cov_mat))

  # Compute the t-value for the confidence interval
  t_val <- qt((1 - level) / 2, df = df.residual(model))

  # Compute the lower and upper bounds of the confidence interval for each coefficient
  ci_lwr <- coef - t_val * se
  ci_upr <- coef + t_val * se

  # Return a data frame with the coefficient estimates and their confidence intervals
  result <- data.frame(
    coefficient = names(coef),
    estimate = coef,
    lwr_ci = ci_lwr,
    upr_ci = ci_upr
  )
  
  return(result)
}

```



```{r, include=FALSE}
# Generate data
set.seed(123)
x <- rnorm(100)
y <- 2*x + rnorm(100)

# Fit a linear regression model
model <- lm(y ~ x)

# Compute the confidence intervals for the coefficients
ci <- compute_CI(model)

# Print the results
print(ci)

```










